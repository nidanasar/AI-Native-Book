"use strict";(globalThis.webpackChunkhackathon_text_book=globalThis.webpackChunkhackathon_text_book||[]).push([[8819],{3238:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-digital-twin/unity-visualization-hri","title":"Chapter 4: High-Fidelity Visualization and Interaction with Unity","description":"Use Unity for realistic rendering and human-robot interaction scenarios","source":"@site/docs/module-2-digital-twin/04-unity-visualization-hri.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/unity-visualization-hri","permalink":"/docs/module-2-digital-twin/unity-visualization-hri","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/04-unity-visualization-hri.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Chapter 4: High-Fidelity Visualization and Interaction with Unity","description":"Use Unity for realistic rendering and human-robot interaction scenarios"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Simulating Sensors for Humanoid Robots","permalink":"/docs/module-2-digital-twin/simulating-sensors"},"next":{"title":"Tutorial - Extras","permalink":"/docs/category/tutorial---extras"}}');var r=i(4848),s=i(8453);const o={sidebar_position:4,title:"Chapter 4: High-Fidelity Visualization and Interaction with Unity",description:"Use Unity for realistic rendering and human-robot interaction scenarios"},a="High-Fidelity Visualization and Interaction with Unity",l={},c=[{value:"Gazebo vs Unity: When to Use Each",id:"gazebo-vs-unity-when-to-use-each",level:2},{value:"Comparing the Two Approaches",id:"comparing-the-two-approaches",level:3},{value:"When to Choose Gazebo",id:"when-to-choose-gazebo",level:3},{value:"When to Choose Unity",id:"when-to-choose-unity",level:3},{value:"The Complementary Approach",id:"the-complementary-approach",level:3},{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Why Game Engines for Robotics?",id:"why-game-engines-for-robotics",level:3},{value:"Unity Robotics Hub",id:"unity-robotics-hub",level:3},{value:"URDF Importer",id:"urdf-importer",level:3},{value:"Basic Scene Setup",id:"basic-scene-setup",level:3},{value:"Connecting Unity to ROS 2",id:"connecting-unity-to-ros-2",level:2},{value:"ROS-TCP-Connector Architecture",id:"ros-tcp-connector-architecture",level:3},{value:"Setting Up the Connection",id:"setting-up-the-connection",level:3},{value:"Message Types and Serialization",id:"message-types-and-serialization",level:3},{value:"Example: Subscribing to Joint States",id:"example-subscribing-to-joint-states",level:3},{value:"Visualizing Robot State",id:"visualizing-robot-state",level:2},{value:"Joint State Visualization",id:"joint-state-visualization",level:3},{value:"TF Visualization",id:"tf-visualization",level:3},{value:"Real-Time Updates",id:"real-time-updates",level:3},{value:"Human-Robot Interaction Scenarios",id:"human-robot-interaction-scenarios",level:2},{value:"Why Unity for HRI?",id:"why-unity-for-hri",level:3},{value:"Virtual Human Models",id:"virtual-human-models",level:3},{value:"VR/AR Integration",id:"vrar-integration",level:3},{value:"Synthetic Data for Vision",id:"synthetic-data-for-vision",level:3},{value:"Summary",id:"summary",level:2}];function d(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"high-fidelity-visualization-and-interaction-with-unity",children:"High-Fidelity Visualization and Interaction with Unity"})}),"\n",(0,r.jsxs)(e.admonition,{title:"Learning Objectives",type:"info",children:[(0,r.jsx)(e.p,{children:"By the end of this chapter, you will be able to:"}),(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Explain when to use Unity vs Gazebo for robotics simulation"}),"\n",(0,r.jsx)(e.li,{children:"Understand the ROS-TCP-Connector architecture for Unity-ROS 2 communication"}),"\n",(0,r.jsx)(e.li,{children:"Describe how to visualize robot state in Unity from ROS 2 data"}),"\n",(0,r.jsx)(e.li,{children:"Appreciate Unity's role in human-robot interaction (HRI) research"}),"\n"]})]}),"\n",(0,r.jsx)(e.h2,{id:"gazebo-vs-unity-when-to-use-each",children:"Gazebo vs Unity: When to Use Each"}),"\n",(0,r.jsxs)(e.p,{children:["Throughout this module, you've used Gazebo for physics simulation. But Gazebo isn't the only tool in the roboticist's toolkit. ",(0,r.jsx)(e.strong,{children:"Unity"}),", a popular game engine, offers capabilities that complement Gazebo's strengths. Understanding when to use each tool\u2014and how to use them together\u2014is essential for modern robotics development."]}),"\n",(0,r.jsx)(e.h3,{id:"comparing-the-two-approaches",children:"Comparing the Two Approaches"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Aspect"}),(0,r.jsx)(e.th,{children:"Gazebo"}),(0,r.jsx)(e.th,{children:"Unity"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Primary Strength"})}),(0,r.jsx)(e.td,{children:"Physics accuracy"}),(0,r.jsx)(e.td,{children:"Visual fidelity"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Physics Engine"})}),(0,r.jsx)(e.td,{children:"DART, ODE, Bullet (scientific)"}),(0,r.jsx)(e.td,{children:"PhysX (game-oriented)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Rendering"})}),(0,r.jsx)(e.td,{children:"Functional"}),(0,r.jsx)(e.td,{children:"Photorealistic"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"ROS Integration"})}),(0,r.jsx)(e.td,{children:"Native (ros_gz_bridge)"}),(0,r.jsx)(e.td,{children:"Via ROS-TCP-Connector"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Learning Curve"})}),(0,r.jsx)(e.td,{children:"Moderate"}),(0,r.jsx)(e.td,{children:"Higher (full game engine)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Best For"})}),(0,r.jsx)(e.td,{children:"Algorithm development"}),(0,r.jsx)(e.td,{children:"Visualization, HRI, training data"})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"when-to-choose-gazebo",children:"When to Choose Gazebo"}),"\n",(0,r.jsxs)(e.p,{children:["Use Gazebo when your priority is ",(0,r.jsx)(e.strong,{children:"physics accuracy"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Control algorithm development"}),": Walking, balancing, manipulation"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensor simulation"}),": LiDAR, depth cameras, IMU with configurable noise"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Rapid prototyping"}),": Quick iteration on robot behaviors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Research validation"}),": Reproducible physics for scientific claims"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Gazebo's physics engines (especially DART) are designed for robotics, with accurate contact modeling, constraint satisfaction, and real-time performance."}),"\n",(0,r.jsx)(e.h3,{id:"when-to-choose-unity",children:"When to Choose Unity"}),"\n",(0,r.jsxs)(e.p,{children:["Use Unity when your priority is ",(0,r.jsx)(e.strong,{children:"visual realism or human interaction"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision system training"}),": Photorealistic images for computer vision"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Human-robot interaction"}),": Scenarios with realistic virtual humans"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Demonstrations"}),": Impressive visualizations for stakeholders"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"VR/AR integration"}),": Immersive robot interfaces"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Synthetic data generation"}),": Large-scale image datasets"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Unity's rendering pipeline can produce images indistinguishable from photographs\u2014something Gazebo cannot match."}),"\n",(0,r.jsx)(e.h3,{id:"the-complementary-approach",children:"The Complementary Approach"}),"\n",(0,r.jsxs)(e.p,{children:["Many robotics teams use ",(0,r.jsx)(e.strong,{children:"both"})," tools:"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                    COMPLEMENTARY WORKFLOW                        \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502   Development Phase        \u2192    Visualization Phase              \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\r\n\u2502   \u2502   Gazebo    \u2502              \u2502    Unity    \u2502                  \u2502\r\n\u2502   \u2502  (physics)  \u2502\u2500\u2500\u2500\u2500ROS 2\u2500\u2500\u2500\u2500\u25ba\u2502  (visuals)  \u2502                  \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   - Test algorithms            - Create demos                    \u2502\r\n\u2502   - Validate control           - Train vision                    \u2502\r\n\u2502   - Generate sensor data       - Study HRI                       \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsxs)(e.p,{children:["Your robot code runs in ROS 2, subscribes to Gazebo's physics simulation, and simultaneously visualizes in Unity. The same ",(0,r.jsx)(e.code,{children:"/joint_states"})," topic drives both the simulated robot and the Unity visualization."]}),"\n",(0,r.jsx)(e.admonition,{title:"Key Insight",type:"tip",children:(0,r.jsx)(e.p,{children:"Gazebo and Unity aren't competitors\u2014they're complementary. Use Gazebo to make your robot work correctly, and Unity to make it look impressive and interact with humans."})}),"\n",(0,r.jsx)(e.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,r.jsx)(e.p,{children:"Unity is a game engine used by millions of developers worldwide. In recent years, it has gained significant traction in robotics research, particularly for simulation and synthetic data generation."}),"\n",(0,r.jsx)(e.h3,{id:"why-game-engines-for-robotics",children:"Why Game Engines for Robotics?"}),"\n",(0,r.jsx)(e.p,{children:"Game engines solve problems that overlap with robotics:"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Game Development Need"}),(0,r.jsx)(e.th,{children:"Robotics Application"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Realistic 3D worlds"}),(0,r.jsx)(e.td,{children:"Robot operating environments"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Character animation"}),(0,r.jsx)(e.td,{children:"Human models for HRI"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Physics simulation"}),(0,r.jsx)(e.td,{children:"Object interactions (though less accurate)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Real-time rendering"}),(0,r.jsx)(e.td,{children:"Sensor visualization"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"VR/AR support"}),(0,r.jsx)(e.td,{children:"Immersive robot interfaces"})]})]})]}),"\n",(0,r.jsx)(e.p,{children:"Unity's mature ecosystem provides tools that would take years to build from scratch."}),"\n",(0,r.jsx)(e.h3,{id:"unity-robotics-hub",children:"Unity Robotics Hub"}),"\n",(0,r.jsxs)(e.p,{children:["Unity provides official robotics support through the ",(0,r.jsx)(e.strong,{children:"Unity Robotics Hub"}),", which includes:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"URDF Importer"}),": Load your robot models directly from URDF files"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS-TCP-Connector"}),": Bridge between Unity and ROS/ROS 2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensor packages"}),": Simulated cameras, LiDAR (basic)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Example projects"}),": Pre-built robotics demonstrations"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"The Robotics Hub makes Unity accessible to roboticists who aren't game developers."}),"\n",(0,r.jsx)(e.h3,{id:"urdf-importer",children:"URDF Importer"}),"\n",(0,r.jsx)(e.p,{children:"The URDF Importer allows you to bring your robot directly into Unity:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Export your URDF (the same file used in Gazebo)"}),"\n",(0,r.jsx)(e.li,{children:"Import into Unity via the URDF Importer package"}),"\n",(0,r.jsx)(e.li,{children:"Unity creates GameObjects for each link"}),"\n",(0,r.jsx)(e.li,{children:"Joints are configured automatically with ArticulationBody components"}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'URDF File                    Unity Scene\r\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\r\n<robot name="humanoid">     Humanoid (GameObject)\r\n  <link name="base">   \u2192      \u251c\u2500\u2500 base (ArticulationBody)\r\n  <link name="arm">    \u2192      \u2502   \u2514\u2500\u2500 arm (ArticulationBody)\r\n  <joint name="...">   \u2192      \u2514\u2500\u2500 [Joint configured automatically]\r\n</robot>\n'})}),"\n",(0,r.jsx)(e.p,{children:"This means your Module 1 URDF can be used in Unity with minimal modification."}),"\n",(0,r.jsx)(e.h3,{id:"basic-scene-setup",children:"Basic Scene Setup"}),"\n",(0,r.jsx)(e.p,{children:"A typical Unity robotics scene contains:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"Unity Scene Hierarchy\r\n\u251c\u2500\u2500 Main Camera\r\n\u251c\u2500\u2500 Directional Light\r\n\u251c\u2500\u2500 Ground Plane (with collision)\r\n\u251c\u2500\u2500 Robot (imported from URDF)\r\n\u2502   \u251c\u2500\u2500 base_link\r\n\u2502   \u251c\u2500\u2500 torso\r\n\u2502   \u2514\u2500\u2500 ... (kinematic chain)\r\n\u251c\u2500\u2500 ROS Connection (script component)\r\n\u2514\u2500\u2500 Environment Objects\n"})}),"\n",(0,r.jsx)(e.p,{children:"Unity uses a left-handed coordinate system (Y-up) while ROS uses right-handed (Z-up). The URDF Importer handles this conversion automatically."}),"\n",(0,r.jsx)(e.h2,{id:"connecting-unity-to-ros-2",children:"Connecting Unity to ROS 2"}),"\n",(0,r.jsxs)(e.p,{children:["Unity and ROS 2 speak different languages. The ",(0,r.jsx)(e.strong,{children:"ROS-TCP-Connector"})," package provides the translation layer, enabling Unity to publish and subscribe to ROS 2 topics."]}),"\n",(0,r.jsx)(e.h3,{id:"ros-tcp-connector-architecture",children:"ROS-TCP-Connector Architecture"}),"\n",(0,r.jsx)(e.p,{children:"The connection works through a TCP socket:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                     CONNECTION ARCHITECTURE                      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502   Unity Application              ROS 2 System                    \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\r\n\u2502   \u2502  Unity Scene     \u2502          \u2502   ROS 2 Nodes    \u2502            \u2502\r\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502            \u2502\r\n\u2502   \u2502  \u2502 ROS        \u2502  \u2502   TCP    \u2502  \u2502 ros_tcp_   \u2502  \u2502            \u2502\r\n\u2502   \u2502  \u2502 Connection \u2502\u25c4\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u25ba\u2502 endpoint   \u2502  \u2502            \u2502\r\n\u2502   \u2502  \u2502 Script     \u2502  \u2502  :10000  \u2502  \u2502   Node     \u2502  \u2502            \u2502\r\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502          \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502            \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   Messages serialized           Messages deserialized            \u2502\r\n\u2502   to ROS format                 and published to topics          \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.p,{children:"Key components:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Unity side"}),": ROS-TCP-Connector package (C# scripts)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"ROS 2 side"}),": ",(0,r.jsx)(e.code,{children:"ros_tcp_endpoint"})," node (Python)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Communication"}),": TCP socket on port 10000 (default)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"setting-up-the-connection",children:"Setting Up the Connection"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"On the ROS 2 side:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Install the endpoint package\r\nsudo apt install ros-humble-ros-tcp-endpoint\r\n\r\n# Or from source\r\ncd ~/ros2_ws/src\r\ngit clone https://github.com/Unity-Technologies/ROS-TCP-Endpoint.git\r\ncd ..\r\ncolcon build\r\nsource install/setup.bash\r\n\r\n# Launch the endpoint\r\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=0.0.0.0\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"On the Unity side:"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Install the ROS-TCP-Connector via Package Manager"}),"\n",(0,r.jsxs)(e.li,{children:["Add ",(0,r.jsx)(e.code,{children:"ROSConnection"})," component to a GameObject"]}),"\n",(0,r.jsx)(e.li,{children:"Configure the ROS IP address and port"}),"\n",(0,r.jsxs)(e.li,{children:["Use ",(0,r.jsx)(e.code,{children:"ROSConnection.Instance"})," to publish/subscribe"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"message-types-and-serialization",children:"Message Types and Serialization"}),"\n",(0,r.jsx)(e.p,{children:"The ROS-TCP-Connector supports standard ROS message types:"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"ROS Message Type"}),(0,r.jsx)(e.th,{children:"Unity Equivalent"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"sensor_msgs/JointState"})}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"JointStateMsg"})})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"geometry_msgs/Pose"})}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"PoseMsg"})})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"std_msgs/Float64"})}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"Float64Msg"})})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"sensor_msgs/Image"})}),(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"ImageMsg"})})]})]})]}),"\n",(0,r.jsx)(e.p,{children:"Messages are serialized to ROS binary format, ensuring compatibility with existing ROS tools."}),"\n",(0,r.jsx)(e.h3,{id:"example-subscribing-to-joint-states",children:"Example: Subscribing to Joint States"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing RosMessageTypes.Sensor;\r\n\r\npublic class JointStateSubscriber : MonoBehaviour\r\n{\r\n    void Start()\r\n    {\r\n        // Subscribe to /joint_states topic\r\n        ROSConnection.GetOrCreateInstance().Subscribe<JointStateMsg>(\r\n            "/joint_states",\r\n            OnJointStateReceived\r\n        );\r\n    }\r\n\r\n    void OnJointStateReceived(JointStateMsg msg)\r\n    {\r\n        // Process joint positions\r\n        for (int i = 0; i < msg.name.Length; i++)\r\n        {\r\n            string jointName = msg.name[i];\r\n            float position = (float)msg.position[i];\r\n\r\n            Debug.Log($"Joint {jointName}: {position} rad");\r\n            // Update robot visualization...\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(e.h2,{id:"visualizing-robot-state",children:"Visualizing Robot State"}),"\n",(0,r.jsx)(e.p,{children:"With the ROS connection established, you can drive your Unity robot visualization from ROS 2 data."}),"\n",(0,r.jsx)(e.h3,{id:"joint-state-visualization",children:"Joint State Visualization"}),"\n",(0,r.jsx)(e.p,{children:"The most common visualization task is showing joint positions:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\r\nusing Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.UrdfImporter;\r\nusing RosMessageTypes.Sensor;\r\n\r\npublic class RobotVisualizer : MonoBehaviour\r\n{\r\n    // Maps joint names to Unity ArticulationBody components\r\n    private Dictionary<string, ArticulationBody> jointMap;\r\n\r\n    void Start()\r\n    {\r\n        // Build joint map from imported URDF\r\n        jointMap = new Dictionary<string, ArticulationBody>();\r\n        foreach (var joint in GetComponentsInChildren<ArticulationBody>())\r\n        {\r\n            jointMap[joint.name] = joint;\r\n        }\r\n\r\n        // Subscribe to joint states\r\n        ROSConnection.GetOrCreateInstance().Subscribe<JointStateMsg>(\r\n            "/joint_states",\r\n            UpdateVisualization\r\n        );\r\n    }\r\n\r\n    void UpdateVisualization(JointStateMsg msg)\r\n    {\r\n        for (int i = 0; i < msg.name.Length; i++)\r\n        {\r\n            if (jointMap.TryGetValue(msg.name[i], out var joint))\r\n            {\r\n                // Set joint target position\r\n                var drive = joint.xDrive;\r\n                drive.target = (float)msg.position[i] * Mathf.Rad2Deg;\r\n                joint.xDrive = drive;\r\n            }\r\n        }\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"tf-visualization",children:"TF Visualization"}),"\n",(0,r.jsx)(e.p,{children:"The TF (Transform) system tracks coordinate frames. Unity can visualize these:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:'// Subscribe to TF and visualize coordinate frames\r\nROSConnection.GetOrCreateInstance().Subscribe<TFMessageMsg>(\r\n    "/tf",\r\n    OnTFReceived\r\n);\r\n\r\nvoid OnTFReceived(TFMessageMsg msg)\r\n{\r\n    foreach (var transform in msg.transforms)\r\n    {\r\n        // Update Unity Transform based on TF data\r\n        string frameName = transform.child_frame_id;\r\n        var position = transform.transform.translation;\r\n        var rotation = transform.transform.rotation;\r\n\r\n        // Apply to corresponding Unity GameObject\r\n        UpdateFrame(frameName, position, rotation);\r\n    }\r\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"real-time-updates",children:"Real-Time Updates"}),"\n",(0,r.jsx)(e.p,{children:"For smooth visualization, consider:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Update rate matching"}),": Match Unity's frame rate to ROS publish rate"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Interpolation"}),": Smooth between received positions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Latency hiding"}),": Predict positions based on velocity"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:"// Simple interpolation for smoother visualization\r\nvoid Update()\r\n{\r\n    foreach (var joint in joints)\r\n    {\r\n        joint.currentPosition = Mathf.Lerp(\r\n            joint.currentPosition,\r\n            joint.targetPosition,\r\n            Time.deltaTime * smoothingFactor\r\n        );\r\n    }\r\n}\n"})}),"\n",(0,r.jsx)(e.h2,{id:"human-robot-interaction-scenarios",children:"Human-Robot Interaction Scenarios"}),"\n",(0,r.jsxs)(e.p,{children:["Unity's greatest strength for robotics lies in ",(0,r.jsx)(e.strong,{children:"Human-Robot Interaction (HRI)"})," research. While Gazebo excels at robot physics, Unity excels at simulating the human side of the equation."]}),"\n",(0,r.jsx)(e.h3,{id:"why-unity-for-hri",children:"Why Unity for HRI?"}),"\n",(0,r.jsx)(e.p,{children:"HRI research requires:"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Requirement"}),(0,r.jsx)(e.th,{children:"Unity Capability"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Realistic humans"}),(0,r.jsx)(e.td,{children:"Character models, animations"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Natural environments"}),(0,r.jsx)(e.td,{children:"Photorealistic rendering"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"User studies"}),(0,r.jsx)(e.td,{children:"VR/AR integration"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Varied scenarios"}),(0,r.jsx)(e.td,{children:"Easy scene modification"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Data collection"}),(0,r.jsx)(e.td,{children:"Built-in analytics"})]})]})]}),"\n",(0,r.jsx)(e.p,{children:"Creating these in Gazebo would require enormous custom development."}),"\n",(0,r.jsx)(e.h3,{id:"virtual-human-models",children:"Virtual Human Models"}),"\n",(0,r.jsx)(e.p,{children:"Unity provides access to:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Character assets"}),": Realistic 3D human models"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Animation systems"}),": Walking, gesturing, facial expressions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Behavior trees"}),": AI-driven human behaviors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Crowd simulation"}),": Multiple humans in a scene"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Example HRI scenarios:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                      HRI SCENARIOS IN UNITY                      \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502   1. Social Navigation                                           \u2502\r\n\u2502      Robot navigates around walking humans                       \u2502\r\n\u2502      Tests: path planning with dynamic obstacles                 \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   2. Handover Tasks                                              \u2502\r\n\u2502      Robot hands object to human                                 \u2502\r\n\u2502      Tests: approach angle, timing, safety                       \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   3. Gesture Recognition                                         \u2502\r\n\u2502      Human gestures, robot responds                              \u2502\r\n\u2502      Tests: perception, interpretation, response                 \u2502\r\n\u2502                                                                  \u2502\r\n\u2502   4. Personal Space                                              \u2502\r\n\u2502      Robot maintains appropriate distance                        \u2502\r\n\u2502      Tests: proxemics, cultural considerations                   \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.h3,{id:"vrar-integration",children:"VR/AR Integration"}),"\n",(0,r.jsx)(e.p,{children:"Unity's VR support enables immersive HRI research:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"First-person robot control"}),": Experience from the robot's perspective"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Telepresence"}),": Control a robot through VR interface"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"User studies"}),": Test human comfort with robot behaviors"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Training"}),": Teach operators to work with robots"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"VR Headset \u2500\u2500\u25ba Unity \u2500\u2500\u25ba ROS 2 \u2500\u2500\u25ba Robot (simulated or real)\r\n     \u2502                      \u2502\r\n     \u2514\u2500\u2500\u2500\u2500 User Input \u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.p,{children:"This pipeline allows a human wearing a VR headset to interact with a robot in real-time, with Unity providing the visual interface and ROS 2 handling robot control."}),"\n",(0,r.jsx)(e.h3,{id:"synthetic-data-for-vision",children:"Synthetic Data for Vision"}),"\n",(0,r.jsx)(e.p,{children:"Unity can generate unlimited training data for vision systems:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Domain randomization"}),": Vary lighting, textures, backgrounds"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Perfect labels"}),": Automatic ground truth (bounding boxes, segmentation)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Edge cases"}),": Simulate rare scenarios (unusual poses, occlusions)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Scale"}),": Generate millions of images without manual labeling"]}),"\n"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-csharp",children:"// Example: Generate training image with labels\r\nvoid CaptureTrainingData()\r\n{\r\n    // Randomize scene\r\n    RandomizeLighting();\r\n    RandomizeHumanPose();\r\n    RandomizeBackground();\r\n\r\n    // Capture image\r\n    var image = camera.Capture();\r\n\r\n    // Generate automatic labels\r\n    var boundingBoxes = GetBoundingBoxes();\r\n    var segmentationMask = GetSegmentationMask();\r\n\r\n    // Save for training\r\n    SaveTrainingExample(image, boundingBoxes, segmentationMask);\r\n}\n"})}),"\n",(0,r.jsx)(e.p,{children:"This synthetic data can train perception systems that transfer to real-world scenarios."}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"In this chapter, you learned how Unity complements Gazebo for humanoid robotics:"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Key Concepts:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Gazebo vs Unity"}),": Different tools for different needs"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Gazebo: Physics accuracy, algorithm development"}),"\n",(0,r.jsx)(e.li,{children:"Unity: Visual fidelity, HRI research, synthetic data"}),"\n",(0,r.jsx)(e.li,{children:"Often used together via ROS 2"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"ROS-TCP-Connector"})," bridges Unity and ROS 2"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"TCP socket communication"}),"\n",(0,r.jsx)(e.li,{children:"Standard ROS message support"}),"\n",(0,r.jsx)(e.li,{children:"Bidirectional data flow"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Robot visualization"})," in Unity"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"URDF Importer loads robot models"}),"\n",(0,r.jsx)(e.li,{children:"Subscribe to /joint_states for real-time updates"}),"\n",(0,r.jsx)(e.li,{children:"TF visualization shows coordinate frames"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"HRI applications"})," leverage Unity's strengths"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Realistic human models and animations"}),"\n",(0,r.jsx)(e.li,{children:"VR/AR integration for immersive research"}),"\n",(0,r.jsx)(e.li,{children:"Synthetic data generation for vision training"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"The Complete Digital Twin Stack:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502                  MODULE 2 COMPLETE STACK                         \u2502\r\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\r\n\u2502                                                                  \u2502\r\n\u2502   Unity (Visualization)          Gazebo (Physics)                \u2502\r\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\r\n\u2502   \u2502 \u2022 Photorealistic   \u2502        \u2502 \u2022 Accurate physics \u2502          \u2502\r\n\u2502   \u2502 \u2022 HRI scenarios    \u2502        \u2502 \u2022 Sensor simulation\u2502          \u2502\r\n\u2502   \u2502 \u2022 VR/AR support    \u2502        \u2502 \u2022 Control testing  \u2502          \u2502\r\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\r\n\u2502             \u2502                              \u2502                     \u2502\r\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\r\n\u2502                        \u2502                                         \u2502\r\n\u2502                  \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510                                   \u2502\r\n\u2502                  \u2502   ROS 2   \u2502                                   \u2502\r\n\u2502                  \u2502 Middleware\u2502                                   \u2502\r\n\u2502                  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                                   \u2502\r\n\u2502                        \u2502                                         \u2502\r\n\u2502                 Your Robot Code                                  \u2502\r\n\u2502                 (same for sim and real!)                         \u2502\r\n\u2502                                                                  \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Module 2 Complete:"})}),"\n",(0,r.jsx)(e.p,{children:"Congratulations! You've completed Module 2: The Digital Twin. You now understand:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"What digital twins are"})," and why simulation matters"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"How to create physics simulations"})," with Gazebo"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"How to simulate sensors"})," for perception development"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"How to visualize and interact"})," using Unity"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"Your humanoid robot now has:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:["A ",(0,r.jsx)(e.strong,{children:"nervous system"})," (ROS 2 from Module 1)"]}),"\n",(0,r.jsxs)(e.li,{children:["A ",(0,r.jsx)(e.strong,{children:"body"})," (URDF from Module 1)"]}),"\n",(0,r.jsxs)(e.li,{children:["An ",(0,r.jsx)(e.strong,{children:"imagination"})," (Gazebo/Unity digital twin from Module 2)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"The robot can rehearse movements, test perception algorithms, and interact with virtual humans\u2014all before touching real hardware. This simulation-first approach is how modern humanoid robots are developed."}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.admonition,{title:"Module Complete",type:"info",children:(0,r.jsx)(e.p,{children:'Congratulations! You have completed Module 2: The Digital Twin. You now understand how to simulate humanoid robots using Gazebo for physics and Unity for visualization. Your robot\'s "imagination" is ready\u2014allowing safe, rapid development before real-world deployment.'})})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>a});var t=i(6540);const r={},s=t.createContext(r);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);